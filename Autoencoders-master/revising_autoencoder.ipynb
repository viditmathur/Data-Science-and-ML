{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense,Activation,Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n"
     ]
    }
   ],
   "source": [
    "ds = pd.read_csv(\"C:/Users/chira/Desktop/machine_learning/new_data/mnist/train.csv\")\n",
    "data = ds.values[:5000,1:]/255.0\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 784)               79184     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 784)               0         \n",
      "=================================================================\n",
      "Total params: 157,684\n",
      "Trainable params: 157,684\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 78,500\n",
      "Trainable params: 78,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 784)               79184     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 784)               0         \n",
      "=================================================================\n",
      "Total params: 79,184\n",
      "Trainable params: 79,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Defining the layers\n",
    "inp = Input(shape=(784,))\n",
    "h1 = Dense(100)\n",
    "a1 = Activation('sigmoid')\n",
    "y = Dense(784,)\n",
    "ya = Activation('sigmoid')\n",
    "\n",
    "#connecting the layers\n",
    "out = ya(y(a1(h1(inp))))\n",
    "\n",
    "#creating autoencoder model\n",
    "model = Model(inputs=[inp],outputs = [out])\n",
    "model.summary()\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# creating encoder model\n",
    "encoder = Model(inputs=[inp],outputs=[a1(h1(inp))])\n",
    "encoder.summary()\n",
    "\n",
    "\n",
    "# creating decoder model\n",
    "dec_inp = Input(shape=(100,))\n",
    "decoder = Model(inputs=[dec_inp],outputs = [ya(y(dec_inp))])\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 1s 116us/step - loss: 0.1125 - acc: 0.0084 - val_loss: 0.0691 - val_acc: 0.0040\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0691 - acc: 0.0120 - val_loss: 0.0673 - val_acc: 0.0160\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0676 - acc: 0.0136 - val_loss: 0.0656 - val_acc: 0.0040\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0655 - acc: 0.0133 - val_loss: 0.0633 - val_acc: 0.0040\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0629 - acc: 0.0133 - val_loss: 0.0608 - val_acc: 0.0040\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0603 - acc: 0.0156 - val_loss: 0.0583 - val_acc: 0.0080\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0577 - acc: 0.0167 - val_loss: 0.0558 - val_acc: 0.0120\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0551 - acc: 0.0207 - val_loss: 0.0534 - val_acc: 0.0080\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0526 - acc: 0.0171 - val_loss: 0.0510 - val_acc: 0.0100\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0503 - acc: 0.0173 - val_loss: 0.0489 - val_acc: 0.0080\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0482 - acc: 0.0167 - val_loss: 0.0470 - val_acc: 0.0100\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0463 - acc: 0.0133 - val_loss: 0.0452 - val_acc: 0.0120\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0445 - acc: 0.0156 - val_loss: 0.0436 - val_acc: 0.0120\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0429 - acc: 0.0147 - val_loss: 0.0420 - val_acc: 0.0100\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0414 - acc: 0.0124 - val_loss: 0.0406 - val_acc: 0.0120\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0399 - acc: 0.0120 - val_loss: 0.0392 - val_acc: 0.0100\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0386 - acc: 0.0113 - val_loss: 0.0378 - val_acc: 0.0140\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0373 - acc: 0.0127 - val_loss: 0.0366 - val_acc: 0.0120\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0360 - acc: 0.0118 - val_loss: 0.0354 - val_acc: 0.0140\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0348 - acc: 0.0100 - val_loss: 0.0343 - val_acc: 0.0120\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0337 - acc: 0.0118 - val_loss: 0.0333 - val_acc: 0.0140\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0327 - acc: 0.0127 - val_loss: 0.0323 - val_acc: 0.0180\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0317 - acc: 0.0118 - val_loss: 0.0314 - val_acc: 0.0140\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0307 - acc: 0.0113 - val_loss: 0.0305 - val_acc: 0.0200\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0298 - acc: 0.0111 - val_loss: 0.0296 - val_acc: 0.0180\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0290 - acc: 0.0116 - val_loss: 0.0289 - val_acc: 0.0240\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0282 - acc: 0.0113 - val_loss: 0.0282 - val_acc: 0.0200\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0274 - acc: 0.0113 - val_loss: 0.0275 - val_acc: 0.0220\n",
      "Epoch 29/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0267 - acc: 0.0120 - val_loss: 0.0268 - val_acc: 0.0120\n",
      "Epoch 30/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0260 - acc: 0.0111 - val_loss: 0.0262 - val_acc: 0.0140\n",
      "Epoch 31/100\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0254 - acc: 0.0102 - val_loss: 0.0256 - val_acc: 0.0140\n",
      "Epoch 32/100\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0248 - acc: 0.0109 - val_loss: 0.0250 - val_acc: 0.0120\n",
      "Epoch 33/100\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0242 - acc: 0.0109 - val_loss: 0.0245 - val_acc: 0.0120\n",
      "Epoch 34/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0236 - acc: 0.0118 - val_loss: 0.0239 - val_acc: 0.0080\n",
      "Epoch 35/100\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0230 - acc: 0.0113 - val_loss: 0.0235 - val_acc: 0.0120\n",
      "Epoch 36/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0225 - acc: 0.0120 - val_loss: 0.0230 - val_acc: 0.0140\n",
      "Epoch 37/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0220 - acc: 0.0118 - val_loss: 0.0225 - val_acc: 0.0100\n",
      "Epoch 38/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0215 - acc: 0.0118 - val_loss: 0.0221 - val_acc: 0.0080\n",
      "Epoch 39/100\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0211 - acc: 0.0107 - val_loss: 0.0217 - val_acc: 0.0120\n",
      "Epoch 40/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0206 - acc: 0.0120 - val_loss: 0.0213 - val_acc: 0.0100\n",
      "Epoch 41/100\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0202 - acc: 0.0098 - val_loss: 0.0209 - val_acc: 0.0080\n",
      "Epoch 42/100\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0198 - acc: 0.0111 - val_loss: 0.0205 - val_acc: 0.0120\n",
      "Epoch 43/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0194 - acc: 0.0116 - val_loss: 0.0202 - val_acc: 0.0100\n",
      "Epoch 44/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0190 - acc: 0.0102 - val_loss: 0.0198 - val_acc: 0.0160\n",
      "Epoch 45/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0186 - acc: 0.0109 - val_loss: 0.0195 - val_acc: 0.0100\n",
      "Epoch 46/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0183 - acc: 0.0107 - val_loss: 0.0192 - val_acc: 0.0120\n",
      "Epoch 47/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0179 - acc: 0.0104 - val_loss: 0.0188 - val_acc: 0.0100\n",
      "Epoch 48/100\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0176 - acc: 0.0102 - val_loss: 0.0185 - val_acc: 0.0120\n",
      "Epoch 49/100\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0173 - acc: 0.0102 - val_loss: 0.0182 - val_acc: 0.0100\n",
      "Epoch 50/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0170 - acc: 0.0104 - val_loss: 0.0180 - val_acc: 0.0060\n",
      "Epoch 51/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0167 - acc: 0.0102 - val_loss: 0.0177 - val_acc: 0.0080\n",
      "Epoch 52/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0164 - acc: 0.0113 - val_loss: 0.0174 - val_acc: 0.0120\n",
      "Epoch 53/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0161 - acc: 0.0104 - val_loss: 0.0171 - val_acc: 0.0120\n",
      "Epoch 54/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0158 - acc: 0.0100 - val_loss: 0.0169 - val_acc: 0.0080\n",
      "Epoch 55/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0155 - acc: 0.0102 - val_loss: 0.0166 - val_acc: 0.0100\n",
      "Epoch 56/100\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0153 - acc: 0.0104 - val_loss: 0.0164 - val_acc: 0.0080\n",
      "Epoch 57/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0150 - acc: 0.0100 - val_loss: 0.0161 - val_acc: 0.0080\n",
      "Epoch 58/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0148 - acc: 0.0100 - val_loss: 0.0159 - val_acc: 0.0100\n",
      "Epoch 59/100\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0146 - acc: 0.0116 - val_loss: 0.0157 - val_acc: 0.0060\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0143 - acc: 0.0100 - val_loss: 0.0155 - val_acc: 0.0080\n",
      "Epoch 61/100\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0141 - acc: 0.0102 - val_loss: 0.0153 - val_acc: 0.0100\n",
      "Epoch 62/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0139 - acc: 0.0100 - val_loss: 0.0150 - val_acc: 0.0080\n",
      "Epoch 63/100\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0137 - acc: 0.0102 - val_loss: 0.0148 - val_acc: 0.0080\n",
      "Epoch 64/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0135 - acc: 0.0109 - val_loss: 0.0147 - val_acc: 0.0100\n",
      "Epoch 65/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0133 - acc: 0.0109 - val_loss: 0.0145 - val_acc: 0.0100\n",
      "Epoch 66/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0131 - acc: 0.0104 - val_loss: 0.0143 - val_acc: 0.0040\n",
      "Epoch 67/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0129 - acc: 0.0089 - val_loss: 0.0141 - val_acc: 0.0040\n",
      "Epoch 68/100\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0127 - acc: 0.0091 - val_loss: 0.0140 - val_acc: 0.0040\n",
      "Epoch 69/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0125 - acc: 0.0096 - val_loss: 0.0138 - val_acc: 0.0100\n",
      "Epoch 70/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0124 - acc: 0.0100 - val_loss: 0.0136 - val_acc: 0.0080\n",
      "Epoch 71/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0122 - acc: 0.0098 - val_loss: 0.0135 - val_acc: 0.0060\n",
      "Epoch 72/100\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0120 - acc: 0.0089 - val_loss: 0.0133 - val_acc: 0.0060\n",
      "Epoch 73/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0119 - acc: 0.0089 - val_loss: 0.0132 - val_acc: 0.0060\n",
      "Epoch 74/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0117 - acc: 0.0098 - val_loss: 0.0130 - val_acc: 0.0080\n",
      "Epoch 75/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0116 - acc: 0.0100 - val_loss: 0.0129 - val_acc: 0.0080\n",
      "Epoch 76/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0114 - acc: 0.0096 - val_loss: 0.0127 - val_acc: 0.0100\n",
      "Epoch 77/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0113 - acc: 0.0096 - val_loss: 0.0126 - val_acc: 0.0100\n",
      "Epoch 78/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0112 - acc: 0.0104 - val_loss: 0.0125 - val_acc: 0.0100\n",
      "Epoch 79/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0110 - acc: 0.0096 - val_loss: 0.0123 - val_acc: 0.0080\n",
      "Epoch 80/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0109 - acc: 0.0096 - val_loss: 0.0122 - val_acc: 0.0080\n",
      "Epoch 81/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0108 - acc: 0.0109 - val_loss: 0.0121 - val_acc: 0.0100\n",
      "Epoch 82/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0106 - acc: 0.0107 - val_loss: 0.0120 - val_acc: 0.0100\n",
      "Epoch 83/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0105 - acc: 0.0102 - val_loss: 0.0119 - val_acc: 0.0080\n",
      "Epoch 84/100\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0104 - acc: 0.0104 - val_loss: 0.0117 - val_acc: 0.0100\n",
      "Epoch 85/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0103 - acc: 0.0102 - val_loss: 0.0116 - val_acc: 0.0120\n",
      "Epoch 86/100\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0102 - acc: 0.0091 - val_loss: 0.0115 - val_acc: 0.0100\n",
      "Epoch 87/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0100 - acc: 0.0096 - val_loss: 0.0114 - val_acc: 0.0080\n",
      "Epoch 88/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0099 - acc: 0.0093 - val_loss: 0.0113 - val_acc: 0.0080\n",
      "Epoch 89/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0098 - acc: 0.0113 - val_loss: 0.0112 - val_acc: 0.0080\n",
      "Epoch 90/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0097 - acc: 0.0096 - val_loss: 0.0111 - val_acc: 0.0080\n",
      "Epoch 91/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0096 - acc: 0.0102 - val_loss: 0.0111 - val_acc: 0.0080\n",
      "Epoch 92/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0095 - acc: 0.0104 - val_loss: 0.0110 - val_acc: 0.0080\n",
      "Epoch 93/100\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0094 - acc: 0.0098 - val_loss: 0.0109 - val_acc: 0.0100\n",
      "Epoch 94/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0093 - acc: 0.0100 - val_loss: 0.0108 - val_acc: 0.0100\n",
      "Epoch 95/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0092 - acc: 0.0091 - val_loss: 0.0107 - val_acc: 0.0080\n",
      "Epoch 96/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0092 - acc: 0.0109 - val_loss: 0.0106 - val_acc: 0.0060\n",
      "Epoch 97/100\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0091 - acc: 0.0104 - val_loss: 0.0105 - val_acc: 0.0100\n",
      "Epoch 98/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0090 - acc: 0.0096 - val_loss: 0.0104 - val_acc: 0.0120\n",
      "Epoch 99/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0089 - acc: 0.0109 - val_loss: 0.0104 - val_acc: 0.0080\n",
      "Epoch 100/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0088 - acc: 0.0100 - val_loss: 0.0103 - val_acc: 0.0100\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(data[:4500],data[:4500],\n",
    "                epochs=100,\n",
    "                shuffle = True,\n",
    "                batch_size=100,\n",
    "                 validation_data=(data[4500:],data[4500:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "ex = encoder.predict(data[:100])\n",
    "print (ex.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n"
     ]
    }
   ],
   "source": [
    "dx = decoder.predict(ex)\n",
    "print(dx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d37dd290b8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAADSdJREFUeJzt3W+oXPWdx/HPJzHxX4NEi2lMst5s/MNWRRuucdWNKIvFLoFYsBKRNdLS9EECW9gHKz6psBRk2Xa3+KBwS2MTaE0r/ouhbBtEvRsiwWuQaBPTxphNswk3lRRinljN/e6De7Jc450zc2fOnDPJ9/0CmZnzPWfO19HP/M7MOXN/jggByGdW0w0AaAbhB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+Q1AV17sw2lxMCfRYR7mS9nkZ+2/fZ3m/7gO3HenkuAPVyt9f2254t6feS7pV0RNKbkh6KiL0l2zDyA31Wx8i/QtKBiDgYEX+RtEXS6h6eD0CNegn/Ikl/nPL4SLHsM2yvsz1me6yHfQGoWC9f+E13aPG5w/qIGJE0InHYDwySXkb+I5KWTHm8WNLR3toBUJdewv+mpGttL7U9V9IaSVuraQtAv3V92B8Rn9reIOk3kmZL2hgRv6usMwB91fWpvq52xmd+oO9qucgHwLmL8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaS6nqJbkmwfkvSRpNOSPo2I4SqawmddcEH5f6ZXX321Ze39998v3fbRRx/tpiWcB3oKf+GeiPiwgucBUCMO+4Gkeg1/SPqt7bdsr6uiIQD16PWw/86IOGr7Sknbbb8XEaNTVyjeFHhjAAZMTyN/RBwtbo9LekHSimnWGYmIYb4MBAZL1+G3fanteWfuS/qqpHeragxAf/Vy2L9A0gu2zzzPLyLivyrpCkDfOSLq25ld387OI8uWLSutHzhwoGXt1ltvLd12bGysq56qcNlll5XWr7/++tL63r17S+unTp2acU/ng4hwJ+txqg9IivADSRF+ICnCDyRF+IGkCD+QVBW/6kOfPfLII6X1Xbt2tazt3r276nYq8+yzz5bW77rrrtL6zTffXFrfv3//jHvKhJEfSIrwA0kRfiApwg8kRfiBpAg/kBThB5LiPP8AmDt3bml9/fr1pfWyn7ZOTEx01VMdrrnmmtL6li1bSuucx+8NIz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJMV5/gEwa1b5e/AVV1xRWn/99derbKdSl1xyScvahRdeWLrte++9V3U7mIKRH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSanue3/ZGSaskHY+IG4tll0v6paQhSYckPRgRf+5fm+e35cuXl9bbTTX99NNPV9lOpYaGhlrWrrrqqtJt+b1+f3Uy8v9M0n1nLXtM0isRca2kV4rHAM4hbcMfEaOSTpy1eLWkTcX9TZLur7gvAH3W7Wf+BRFxTJKK2yurawlAHfp+bb/tdZLW9Xs/AGam25F/3PZCSSpuj7daMSJGImI4Ioa73BeAPug2/FslrS3ur5X0UjXtAKhL2/DbfkbSG5Kut33E9rckPSnpXtt/kHRv8RjAOcQRUd/O7Pp2dg4ZHR0trc+fP7+0ftNNN1XZTqVWrVrVsvbyyy+XbnvRRReV1j/++OOuejrfRYQ7WY8r/ICkCD+QFOEHkiL8QFKEH0iK8ANJ8ae7B8ANN9xQWn/qqadq6qR6K1eubLoFtMDIDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJcZ6/Brfddltpvd1Pdnfs2FFlO7W64447WtbGx8dLt52YmKi6HUzByA8kRfiBpAg/kBThB5Ii/EBShB9IivADSXGevwazZ88urbc7n3348OEq26lUu3+3iy++uGXtxRdfLN32k08+6aondIaRH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSanue3/ZGSaskHY+IG4tlT0j6tqQ/Fas9HhG/7leT57tZs8rfgx9++OHS+muvvdaytnz58tJtFy1aVFq/5557Suvz5s0rrS9btqxlbfPmzaXbor86Gfl/Jum+aZb/R0TcUvxD8IFzTNvwR8SopBM19AKgRr185t9ge4/tjbbL/w4VgIHTbfh/LGmZpFskHZP0g1Yr2l5ne8z2WJf7AtAHXYU/IsYj4nRETEj6iaQVJeuORMRwRAx32ySA6nUVftsLpzz8uqR3q2kHQF06OdX3jKS7JX3R9hFJ35N0t+1bJIWkQ5K+08ceAfSBI6K+ndn17WyAtPvN+86dO0vrK1a0/FQlSTp9+nTL2qlTp0q3PXjwYGl9dHS0tL59+/bS+rZt21rWVq5cWbrtuTxfQZMiwp2sxxV+QFKEH0iK8ANJEX4gKcIPJEX4gaT40901KDsVJ0m33357ab1smmtJOnnyZMvanj17Srft1eLFi7ve9ujRoxV2gpli5AeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpDjPPwDaTdE9yD9t3bBhQ9MtoEuM/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOf50ZPrrruutF729wQ++OCDqtvBDDDyA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSbc/z214iabOkL0makDQSET+yfbmkX0oaknRI0oMR8ef+tYomDA0NldZXrVpVWn/ggQda1uqcHh6f18nI/6mkf46Iv5H0t5LW2/6ypMckvRIR10p6pXgM4BzRNvwRcSwidhf3P5K0T9IiSaslbSpW2yTp/n41CaB6M/rMb3tI0lck7ZK0ICKOSZNvEJKurLo5AP3T8bX9tr8g6TlJ342Ik7Y73W6dpHXdtQegXzoa+W3P0WTwfx4RzxeLx20vLOoLJR2fbtuIGImI4YgYrqJhANVoG35PDvE/lbQvIn44pbRV0tri/lpJL1XfHoB+6eSw/05J/yjpHdtvF8sel/SkpF/Z/pakw5K+0Z8W0aSlS5eW1ufMmVNaP3HiRJXtoEJtwx8ROyS1+oD/99W2A6AuXOEHJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iiim60VdXX311y9qOHTtq7ARnY+QHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaRc5zTJtpmT+RyzaNGi0vobb7xRWt+5c2fL2po1a7rqCeUioqO59Bj5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCptuf5bS+RtFnSlyRNSBqJiB/ZfkLStyX9qVj18Yj4dZvn4jw/0GednufvJPwLJS2MiN2250l6S9L9kh6UdCoi/r3Tpgg/0H+dhr/tX/KJiGOSjhX3P7K9T1L5ZV8ABt6MPvPbHpL0FUm7ikUbbO+xvdH2/BbbrLM9Znusp04BVKrja/ttf0HS65K+HxHP214g6UNJIelfNfnR4JttnoPDfqDPKvvML0m250jaJuk3EfHDaepDkrZFxI1tnofwA31W2Q97bFvSTyXtmxr84ovAM74u6d2ZNgmgOZ182/93kv5b0juaPNUnSY9LekjSLZo87D8k6TvFl4Nlz8XID/RZpYf9VSH8QP/xe34ApQg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJtf0DnhX7UNL/THn8xWLZIBrU3ga1L4neulVlb1d3umKtv+f/3M7tsYgYbqyBEoPa26D2JdFbt5rqjcN+ICnCDyTVdPhHGt5/mUHtbVD7kuitW4301uhnfgDNaXrkB9CQRsJv+z7b+20fsP1YEz20YvuQ7Xdsv930FGPFNGjHbb87Zdnltrfb/kNxO+00aQ319oTt/y1eu7dt/0NDvS2x/artfbZ/Z/ufiuWNvnYlfTXyutV+2G97tqTfS7pX0hFJb0p6KCL21tpIC7YPSRqOiMbPCdu+S9IpSZvPzIZk+98knYiIJ4s3zvkR8S8D0tsTmuHMzX3qrdXM0o+qwdeuyhmvq9DEyL9C0oGIOBgRf5G0RdLqBvoYeBExKunEWYtXS9pU3N+kyf95ateit4EQEcciYndx/yNJZ2aWbvS1K+mrEU2Ef5GkP055fESDNeV3SPqt7bdsr2u6mWksODMzUnF7ZcP9nK3tzM11Omtm6YF57bqZ8bpqTYR/utlEBumUw50RsVzS1yStLw5v0ZkfS1qmyWncjkn6QZPNFDNLPyfpuxFxssleppqmr0ZetybCf0TSkimPF0s62kAf04qIo8XtcUkvaPJjyiAZPzNJanF7vOF+/l9EjEfE6YiYkPQTNfjaFTNLPyfp5xHxfLG48dduur6aet2aCP+bkq61vdT2XElrJG1toI/PsX1p8UWMbF8q6asavNmHt0paW9xfK+mlBnv5jEGZubnVzNJq+LUbtBmvG7nIpziV8Z+SZkvaGBHfr72Jadj+a02O9tLkLx5/0WRvtp+RdLcmf/U1Lul7kl6U9CtJfyXpsKRvRETtX7y16O1uzXDm5j711mpm6V1q8LWrcsbrSvrhCj8gJ67wA5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+Q1P8BaJPKfSiwBf8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d37dcc7198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d35271cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n =np.random.choice(range(100))\n",
    "plt.figure(0)\n",
    "plt.imshow(data[n].reshape(28,28),cmap='gray')\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(dx[n].reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
